{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering phase 1\n",
    "\n",
    "- Remove unnecessary columns to reduce dataframe size\n",
    "- Filter train records according to min/max langtitude and longitude in grid info\n",
    "- Generate grid info and aggregate records accroding to VIN and grid id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import timeit\n",
    "%matplotlib inline\n",
    "\n",
    "# loading training files\n",
    "ecar_training_data_path = 'data/training/ecar/'\n",
    "rcar_training_data_path = 'data/training/rcar/'\n",
    "\n",
    "ecar_output_filepath = 'data/training/ecar/processed/ecar_training.csv'\n",
    "rcar_output_filepath = 'data/training/rcar/processed/rcar_training.csv'\n",
    "\n",
    "weather_filepath = 'data/weather.csv'\n",
    "training_features_filepath = 'data/training.csv' \n",
    "\n",
    "ecar_filenames = [f for f in os.listdir(ecar_training_data_path)]\n",
    "rcar_filenames = [f for f in os.listdir(rcar_training_data_path)]\n",
    "\n",
    "# define drop columns\n",
    "ecar_drop_columns = ['work_mode','mileage','avg_fuel_consumption','system_mode']\n",
    "rcar_drop_columns = ['power_mode','mileage','fuel_consumption']\n",
    "common_drop_columns = ['lat','lon','date_time']\n",
    "\n",
    "# loading grid min/max lantitude and longitude\n",
    "grids = pd.read_csv('data/grid_info.csv')\n",
    "grid_max_lantitude = grids['latitude_to'].max()\n",
    "grid_min_lantitude = grids['latitude_from'].min()\n",
    "grid_max_longitude = grids['longitude_to'].max()\n",
    "grid_min_longitude = grids['longitude_from'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down_lat_lon(df):\n",
    "    df['lat'] = df.lat.round(3)\n",
    "    df['lon'] = df.lon.round(3)\n",
    "    return df\n",
    "        \n",
    "def filter_data_by_lan_lon(df):\n",
    "    df = df[(df.lat >= grid_min_lantitude ) & (df.lat <= grid_max_lantitude)]\n",
    "    df = df[(df.lon >= grid_min_longitude ) & (df.lon <= grid_max_longitude)]\n",
    "    return df\n",
    "\n",
    "def add_grid_id(df):\n",
    "    df_with_grid_id = pd.DataFrame(index=[0], columns=['car_id', 'date_time','speed','lat','lon','grid_id'])\n",
    "    df_with_grid_id = df_with_grid_id.fillna(-1)\n",
    "    for i in range(len(grids)):\n",
    "        min_lan, max_lan = grids['latitude_from'][i], grids['latitude_to'][i]\n",
    "        min_lon, max_lon, grid_id = grids['longitude_from'][i], grids['longitude_to'][i], grids['grid_id'][i]\n",
    "        df_ = df[(df.lat >= min_lan ) & (df.lat <= max_lan)]\n",
    "        df_ = df_[(df_.lon >= min_lon ) & (df_.lon <= max_lon)]\n",
    "        df_['grid_id'] = grid_id\n",
    "        df_with_grid_id = df_with_grid_id.append(df_)\n",
    "    return df_with_grid_id\n",
    "\n",
    "def format_date(date_time):\n",
    "    return date_time[:-9].replace('-','')\n",
    "\n",
    "def retrieve_hour(date_time):\n",
    "    return date_time[-8:-6]\n",
    "\n",
    "def preprocess_data(dataType='rcar'):\n",
    "    # init run time\n",
    "    start = timeit.default_timer()\n",
    "    # define common variables\n",
    "    filenames = rcar_filenames\n",
    "    filepath = rcar_training_data_path\n",
    "    drop_columns = rcar_drop_columns\n",
    "    output_filepath = rcar_output_filepath    \n",
    "    \n",
    "    if dataType == 'ecar':\n",
    "        filenames = ecar_filenames\n",
    "        filepath = ecar_training_data_path\n",
    "        drop_columns = ecar_drop_columns\n",
    "        output_filepath = ecar_output_filepath\n",
    "        \n",
    "    # if file is already exist return\n",
    "    if os.path.exists(output_filepath):\n",
    "        print(output_filepath + \" already existed, will return directly\")\n",
    "        return\n",
    "    \n",
    "    df_ = pd.DataFrame(index=[0], columns=['car_id', 'date','hour','speed', 'grid_id'])\n",
    "    df_ = df_.fillna(-1)\n",
    "    for filename in filenames:\n",
    "        # if is directory skip\n",
    "        if os.path.isdir(filepath + filename):\n",
    "            continue\n",
    "        # loading data\n",
    "        df = pd.read_csv(filepath + filename, low_memory=False)\n",
    "        # drop uncessary columns\n",
    "        df = df.drop(columns=drop_columns)\n",
    "        # filter data by lat and lon\n",
    "        df = filter_data_by_lan_lon(df)\n",
    "        # format data_time column\n",
    "        df['hour'] = df['date_time'].apply(lambda x : retrieve_hour(x))\n",
    "        df['date'] = df['date_time'].apply(lambda x : format_date(x))\n",
    "        # generate new column grid_id\n",
    "        df = add_grid_id(df)\n",
    "        # filter data by grid_id\n",
    "        df = df[df.grid_id != -1]\n",
    "        # drop date_time, lat and lon\n",
    "        df = df.drop(columns=common_drop_columns)\n",
    "        # group by below column and get average speed for each record\n",
    "        df = df.groupby(['car_id', 'date','hour','grid_id'], as_index=False).mean()\n",
    "        # round average speed\n",
    "        df.speed = df.speed.round(3)\n",
    "        # appending df\n",
    "        df_ = df_.append(df)\n",
    "        # remove grid_id = -1\n",
    "        df_ = df_[df_.grid_id != -1]\n",
    "    # print log and total time\n",
    "    print(\"Finish process all the file, total cost:[\", timeit.default_timer() - start ,\"] seconds.\")\n",
    "    # write final file\n",
    "    df_.to_csv(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish all the file, total cost:[ 344.8129758159416 ]\n"
     ]
    }
   ],
   "source": [
    "preprocess_data('rcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/training/ecar/processed/ecar_training.csv already existed, will return directly\n"
     ]
    }
   ],
   "source": [
    "preprocess_data('ecar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering phase 2\n",
    "- Merge ecar and rcar training data\n",
    "- Drop column speed and car_id first(these 2 columns maybe used in future but let's try a simple solution first)\n",
    "- Aggregate training data and calculate total number of cars per day/per hour/per grid\n",
    "- Merge training data with weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_phase1_data():\n",
    "    # loading files\n",
    "    ecar = pd.read_csv(ecar_output_filepath)\n",
    "    rcar = pd.read_csv(rcar_output_filepath)\n",
    "    weather = pd.read_csv(weather_filepath)\n",
    "    # merge data\n",
    "    df = ecar.append(rcar)\n",
    "    # remove unnamed column\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    # drop car id and speed\n",
    "    df = df.drop(columns=['car_id','speed'])\n",
    "    # add column count\n",
    "    df['count'] = 1\n",
    "    # aggregate data by date,hour and grid id\n",
    "    df = df.groupby(['date','hour','grid_id'], as_index=False).sum()\n",
    "    # remove unecessary row\n",
    "    df = df[(df.date != 20161230 ) & (df.date != 20170101)]\n",
    "    # format weather date\n",
    "    weather['date'] = weather['date'].apply(lambda x : x.replace('-', ''))\n",
    "    weather['date'] = weather['date'].astype(np.int64)\n",
    "    # merge data set\n",
    "    df = pd.merge(df, weather, on=['date', 'hour'], how='left')\n",
    "    # write to disk\n",
    "    final_df.to_csv(training_features_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_phase1_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
