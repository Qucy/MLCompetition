{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "- Remove unnecessary columns to reduce dataframe size\n",
    "- Filter train records according to min/max langtitude and longitude in grid info\n",
    "- Generate grid info and aggregate records accroding to VIN and grid id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import timeit\n",
    "%matplotlib inline\n",
    "\n",
    "# loading training files\n",
    "ecar_training_data_path = 'data/training/ecar/'\n",
    "rcar_training_data_path = 'data/training/rcar/'\n",
    "\n",
    "ecar_filenames = [f for f in os.listdir(ecar_training_data_path)]\n",
    "rcar_filenames = [f for f in os.listdir(rcar_training_data_path)]\n",
    "\n",
    "# define drop columns\n",
    "ecar_drop_columns = ['work_mode','mileage','avg_fuel_consumption','system_mode']\n",
    "rcar_drop_columns = ['power_mode','mileage','fuel_consumption']\n",
    "common_drop_columns = ['lat','lon','date_time']\n",
    "\n",
    "# loading grid min/max lantitude and longitude\n",
    "grids = pd.read_csv('data/grid_info.csv')\n",
    "grid_max_lantitude = grids['latitude_to'].max()\n",
    "grid_min_lantitude = grids['latitude_from'].min()\n",
    "grid_max_longitude = grids['longitude_to'].max()\n",
    "grid_min_longitude = grids['longitude_from'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down_lat_lon(df):\n",
    "    df['lat'] = df.lat.round(3)\n",
    "    df['lon'] = df.lon.round(3)\n",
    "    return df\n",
    "        \n",
    "def filter_data_by_lan_lon(df):\n",
    "    df = df[(df.lat >= grid_min_lantitude ) & (df.lat <= grid_max_lantitude)]\n",
    "    df = df[(df.lon >= grid_min_longitude ) & (df.lon <= grid_max_longitude)]\n",
    "    return df\n",
    "\n",
    "def add_grid_id(df):\n",
    "    df_with_grid_id = pd.DataFrame(index=[0], columns=['car_id', 'date_time','speed','lat','lon','grid_id'])\n",
    "    df_with_grid_id = df_with_grid_id.fillna(-1)\n",
    "    for i in range(len(grids)):\n",
    "        min_lan, max_lan = grids['latitude_from'][i], grids['latitude_to'][i]\n",
    "        min_lon, max_lon, grid_id = grids['longitude_from'][i], grids['longitude_to'][i], grids['grid_id'][i]\n",
    "        df_ = df[(df.lat >= min_lan ) & (df.lat <= max_lan)]\n",
    "        df_ = df_[(df_.lon >= min_lon ) & (df_.lon <= max_lon)]\n",
    "        df_['grid_id'] = grid_id\n",
    "        df_with_grid_id = df_with_grid_id.append(df_)\n",
    "    return df_with_grid_id\n",
    "\n",
    "def format_date(date_time):\n",
    "    return date_time[:-9].replace('-','')\n",
    "\n",
    "def retrieve_hour(date_time):\n",
    "    return date_time[-8:-6]\n",
    "\n",
    "def preprocess_data(dataType='rcar'):\n",
    "    # define common variables\n",
    "    filenames = rcar_filenames\n",
    "    filepath = rcar_training_data_path\n",
    "    drop_columns = rcar_drop_columns\n",
    "    \n",
    "    if dataType == 'ecar':\n",
    "        filenames = ecar_filenames\n",
    "        filepath = ecar_training_data_path\n",
    "        drop_columns = ecar_drop_columns\n",
    "    \n",
    "    df_ = pd.DataFrame(index=[0], columns=['car_id', 'date','hour','speed', 'grid_id'])\n",
    "    df_ = df_.fillna(-1)\n",
    "    for filename in filenames:\n",
    "        # if is directory skip\n",
    "        if os.path.isdir(filepath + filename):\n",
    "            continue\n",
    "        # if file is already generated skip\n",
    "        if os.path.exists(filepath + 'processed/' + filename):\n",
    "            continue\n",
    "        # init run time\n",
    "        start = timeit.default_timer()\n",
    "        # loading data\n",
    "        df = pd.read_csv(filepath + filename)\n",
    "        # drop uncessary columns\n",
    "        df = df.drop(columns=drop_columns)\n",
    "        # filter data by lat and lon\n",
    "        df = filter_data_by_lan_lon(df)\n",
    "        # format data_time column\n",
    "        df['hour'] = df['date_time'].apply(lambda x : retrieve_hour(x))\n",
    "        df['date'] = df['date_time'].apply(lambda x : format_date(x))\n",
    "        # generate new column grid_id\n",
    "        df = add_grid_id(df)\n",
    "        # filter data by grid_id\n",
    "        df = df[df.grid_id != -1]\n",
    "        # drop lat and lon\n",
    "        df = df.drop(columns=common_drop_columns)\n",
    "        # appending df\n",
    "        df_ = df_.append(df)\n",
    "        # remove grid_id = -1\n",
    "        df_ = df_[df_.grid_id != -1]\n",
    "        # group by below column and get average speed for each record\n",
    "        df_ = df.groupby(['car_id', 'date','hour','grid_id'], as_index=False).mean()\n",
    "        # round average speed\n",
    "        df_.speed = df_.speed.round(3)\n",
    "        # write final file\n",
    "        df_.to_csv(filepath + 'processed/' + filename)\n",
    "        # log run time\n",
    "        print(\"Finish preprocess file:[\", filename, \"] total cost:[\", timeit.default_timer() - start ,\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data('rcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data('ecar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
