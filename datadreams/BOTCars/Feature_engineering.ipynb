{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering phase 1\n",
    "\n",
    "- Remove unnecessary columns to reduce dataframe size\n",
    "- Filter train records according to min/max langtitude and longitude in grid info\n",
    "- Generate grid info and aggregate records accroding to VIN and grid id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import timeit\n",
    "%matplotlib inline\n",
    "\n",
    "# loading training files\n",
    "ecar_training_data_path = 'data/training/ecar/'\n",
    "rcar_training_data_path = 'data/training/rcar/'\n",
    "\n",
    "ecar_output_filepath = 'data/training/ecar/processed/ecar_training.csv'\n",
    "rcar_output_filepath = 'data/training/rcar/processed/rcar_training.csv'\n",
    "\n",
    "weather_filepath = 'data/weather.csv'\n",
    "training_features_filepath = 'data/training.csv'\n",
    "test_features_filepath = 'data/test.csv'\n",
    "submission_filepath = 'data/submit_samples.csv'\n",
    "\n",
    "ecar_filenames = [f for f in os.listdir(ecar_training_data_path)]\n",
    "rcar_filenames = [f for f in os.listdir(rcar_training_data_path)]\n",
    "\n",
    "# define drop columns\n",
    "ecar_drop_columns = ['work_mode','mileage','avg_fuel_consumption','system_mode']\n",
    "rcar_drop_columns = ['power_mode','mileage','fuel_consumption']\n",
    "common_drop_columns = ['lat','lon','date_time']\n",
    "\n",
    "# training features\n",
    "feature_columns = ['year','month','day','hour','weekday','grid_id',\n",
    "                   'temperture','rainy','holiday','car_number']\n",
    "\n",
    "feature_columns_with_speed = ['year','month','day','hour','weekday','grid_id',\n",
    "                   'temperture','rainy','holiday','speed','car_number']\n",
    "\n",
    "feature_drop_to_calc_avg_car_number = ['year','month','day','temperture','rainy','holiday']\n",
    "\n",
    "\n",
    "# loading grid min/max lantitude and longitude\n",
    "grids = pd.read_csv('data/grid_info.csv')\n",
    "grid_max_lantitude = grids['latitude_to'].max()\n",
    "grid_min_lantitude = grids['latitude_from'].min()\n",
    "grid_max_longitude = grids['longitude_to'].max()\n",
    "grid_min_longitude = grids['longitude_from'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down_lat_lon(df):\n",
    "    df['lat'] = df.lat.round(3)\n",
    "    df['lon'] = df.lon.round(3)\n",
    "    return df\n",
    "        \n",
    "def filter_data_by_lan_lon(df):\n",
    "    df = df[(df.lat >= grid_min_lantitude ) & (df.lat <= grid_max_lantitude)]\n",
    "    df = df[(df.lon >= grid_min_longitude ) & (df.lon <= grid_max_longitude)]\n",
    "    return df\n",
    "\n",
    "def add_grid_id(df):\n",
    "    df_with_grid_id = pd.DataFrame(index=[0], columns=['car_id', 'date_time','speed','lat','lon','grid_id'])\n",
    "    df_with_grid_id = df_with_grid_id.fillna(-1)\n",
    "    for i in range(len(grids)):\n",
    "        min_lan, max_lan = grids['latitude_from'][i], grids['latitude_to'][i]\n",
    "        min_lon, max_lon, grid_id = grids['longitude_from'][i], grids['longitude_to'][i], grids['grid_id'][i]\n",
    "        df_ = df[(df.lat >= min_lan ) & (df.lat <= max_lan)]\n",
    "        df_ = df_[(df_.lon >= min_lon ) & (df_.lon <= max_lon)]\n",
    "        df_['grid_id'] = grid_id\n",
    "        df_with_grid_id = df_with_grid_id.append(df_)\n",
    "    return df_with_grid_id\n",
    "\n",
    "def format_date(date_time):\n",
    "    return date_time[:-9].replace('-','')\n",
    "\n",
    "def retrieve_hour(date_time):\n",
    "    return date_time[-8:-6]\n",
    "\n",
    "def preprocess_data(dataType='rcar'):\n",
    "    # init run time\n",
    "    start = timeit.default_timer()\n",
    "    # define common variables\n",
    "    filenames = rcar_filenames\n",
    "    filepath = rcar_training_data_path\n",
    "    drop_columns = rcar_drop_columns\n",
    "    output_filepath = rcar_output_filepath    \n",
    "    \n",
    "    if dataType == 'ecar':\n",
    "        filenames = ecar_filenames\n",
    "        filepath = ecar_training_data_path\n",
    "        drop_columns = ecar_drop_columns\n",
    "        output_filepath = ecar_output_filepath\n",
    "        \n",
    "    # if file is already exist return\n",
    "    if os.path.exists(output_filepath):\n",
    "        print(output_filepath + \" already existed, will return directly\")\n",
    "        return\n",
    "    \n",
    "    df_ = pd.DataFrame(index=[0], columns=['car_id', 'date','hour','speed', 'grid_id'])\n",
    "    df_ = df_.fillna(-1)\n",
    "    for filename in filenames:\n",
    "        # if is directory skip\n",
    "        if os.path.isdir(filepath + filename):\n",
    "            continue\n",
    "        # loading data\n",
    "        df = pd.read_csv(filepath + filename, low_memory=False)\n",
    "        # drop uncessary columns\n",
    "        df = df.drop(columns=drop_columns)\n",
    "        # filter data by lat and lon\n",
    "        df = filter_data_by_lan_lon(df)\n",
    "        # format data_time column\n",
    "        df['hour'] = df['date_time'].apply(lambda x : retrieve_hour(x))\n",
    "        df['date'] = df['date_time'].apply(lambda x : format_date(x))\n",
    "        # generate new column grid_id\n",
    "        df = add_grid_id(df)\n",
    "        # filter data by grid_id\n",
    "        df = df[df.grid_id != -1]\n",
    "        # drop date_time, lat and lon\n",
    "        df = df.drop(columns=common_drop_columns)\n",
    "        # group by below column and get average speed for each record\n",
    "        df = df.groupby(['car_id', 'date','hour','grid_id'], as_index=False).mean()\n",
    "        # round average speed\n",
    "        df.speed = df.speed.round(3)\n",
    "        # appending df\n",
    "        df_ = df_.append(df)\n",
    "        # remove grid_id = -1\n",
    "        df_ = df_[df_.grid_id != -1]\n",
    "    # print log and total time\n",
    "    print(\"Finish process all the files, total cost:[\", timeit.default_timer() - start ,\"] seconds.\")\n",
    "    # write final file\n",
    "    df_.to_csv(output_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish all the file, total cost:[ 344.8129758159416 ]\n"
     ]
    }
   ],
   "source": [
    "preprocess_data('rcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/training/ecar/processed/ecar_training.csv already existed, will return directly\n"
     ]
    }
   ],
   "source": [
    "preprocess_data('ecar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering phase 2\n",
    "- Merge ecar and rcar training data\n",
    "- Drop column speed and car_id first(these 2 columns maybe used in future but let's try a simple solution first)\n",
    "- Aggregate training data and calculate total number of cars per day/per hour/per grid\n",
    "- Merge training data with weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_weather_data():\n",
    "    # split date to year, month and day, adding one more column weekday\n",
    "    df = pd.read_csv(weather_filepath)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['weekday'] = df['date'].dt.weekday\n",
    "    # format date yyyy-mm-dd to yyyymmdd for later join with car's data\n",
    "    df['date'] = df['date'].astype(str)\n",
    "    df['date'] = df['date'].apply(lambda x : x.replace('-', ''))\n",
    "    df['date'] = df['date'].astype(np.int64)\n",
    "    return df\n",
    "\n",
    "def preprocess_phase1_data(use_full_data=True, use_avg_car_number=False):    \n",
    "    # loading files\n",
    "    ecar = pd.read_csv(ecar_output_filepath)\n",
    "    rcar = pd.read_csv(rcar_output_filepath)\n",
    "    weather = preprocess_weather_data()\n",
    "    full_data = generate_full_data_set()    \n",
    "    # merge weather with full data\n",
    "    f_weather = pd.merge(full_data, weather, on=['year','month','day','hour'], how='left')    \n",
    "    # merge ecar and rcar data\n",
    "    df = ecar.append(rcar)    \n",
    "    # drop car id and speed\n",
    "    df = df.drop(columns=['car_id','speed'])    \n",
    "    # add column car_number\n",
    "    df['car_number'] = 1    \n",
    "    # aggregate data by date,hour and grid id\n",
    "    df = df.groupby(['date','hour','grid_id'], as_index=False).sum()    \n",
    "    # remove unecessary row\n",
    "    df = df[(df.date != 20161230 ) & (df.date != 20170101)]    \n",
    "    # merge data set\n",
    "    df = pd.merge(f_weather, df, on=['date','hour','grid_id'], how='left')    \n",
    "    # remove 23:00 ~ 8:00 data\n",
    "    df = remove_other_hours_data(df)    \n",
    "    # remove CNY\n",
    "    df = remove_chinese_new_year_data(df)    \n",
    "    # handle N/A car number\n",
    "    df = handle_na_car_number(df, use_full_data, use_avg_car_number)    \n",
    "    # write to disk\n",
    "    df.to_csv(training_features_filepath, columns=feature_columns, index=False)\n",
    "    \n",
    "def generate_average_speed_per_grid_weekday_hour():\n",
    "    ecar = pd.read_csv(ecar_output_filepath)\n",
    "    rcar = pd.read_csv(rcar_output_filepath)\n",
    "    df = ecar.append(rcar)\n",
    "    # remove outlier\n",
    "    df = df[(df.date != 20161230 ) & (df.date != 20170101)]\n",
    "    # remove CNY\n",
    "    df = df[(df.date != 20170127 ) & (df.date != 20170128)]\n",
    "    df = df[(df.date != 20170129 ) & (df.date != 20170130)]\n",
    "    df = df[(df.date != 20170131 ) & (df.date != 20170201)]\n",
    "    df = df[(df.date != 20170202 )]\n",
    "    # add new column weekday\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n",
    "    df['weekday'] = df['date'].dt.weekday\n",
    "    # drop uncessary columns\n",
    "    df = df.drop(columns=['date','car_id'])\n",
    "    # get average speed per grid, per weekday, per hour\n",
    "    df = df.groupby(['weekday','hour','grid_id'], as_index=False).mean()\n",
    "    # round speed\n",
    "    df['speed'] = df.speed.round() \n",
    "    df['speed'] = df['speed'].astype(int)\n",
    "    return df\n",
    "\n",
    "# train data from 2017-01-02 to 2017-03-12\n",
    "def generate_full_data_set():\n",
    "    jan_df = generate_data_by_range(2017,1,2,31,0,23,1,50)\n",
    "    feb_df = generate_data_by_range(2017,2,1,28,0,23,1,50)\n",
    "    march_df = generate_data_by_range(2017,3,1,12,0,23,1,50)\n",
    "    df = jan_df.append(feb_df)\n",
    "    df = df.append(march_df)\n",
    "    return df\n",
    "    \n",
    "def generate_data_by_range(year, month, start_date, end_date, start_time, end_time, start_gid, end_gid):\n",
    "    # define arrays\n",
    "    years = []\n",
    "    months = []\n",
    "    days = []\n",
    "    hours = []\n",
    "    grid_id = []\n",
    "    # generate grid id, date and hour according to criteria\n",
    "    for date in range(start_date, end_date+1):\n",
    "        for time in range(start_time, end_time+1):\n",
    "            for gid in range(start_gid, end_gid+1):\n",
    "                years.append(year)\n",
    "                months.append(month)\n",
    "                days.append(date)\n",
    "                hours.append(time)\n",
    "                grid_id.append(gid)\n",
    "    # genreate dataframe            \n",
    "    df = pd.DataFrame(data={'year':year,'month':month,'day':days, 'hour': hours, 'grid_id':grid_id})\n",
    "    df['flag'] = 0\n",
    "    df=df.reindex(columns=['year','month','day','hour','grid_id','flag'])\n",
    "    return df\n",
    "\n",
    "def append_avg_speed_to_train_and_test():\n",
    "    # loading train and test\n",
    "    train = pd.read_csv(training_features_filepath)\n",
    "    test = pd.read_csv(test_features_filepath)\n",
    "    # if already append speed then return\n",
    "    if 'speed' in train.columns:\n",
    "        return\n",
    "    # generate \n",
    "    avg_spd = generate_average_speed_per_grid_weekday_hour()\n",
    "    # merge with train\n",
    "    train = pd.merge(train, avg_spd, on=['grid_id','weekday','hour'], how='left')\n",
    "    # merge with test\n",
    "    test = pd.merge(test, avg_spd, on=['grid_id','weekday','hour'], how='left')\n",
    "    # generate new train and test data set\n",
    "    train.to_csv(training_features_filepath, columns=feature_columns_with_speed, index=False)\n",
    "    test.to_csv(test_features_filepath, columns=feature_columns_with_speed, index=False)\n",
    "    \n",
    "def remove_chinese_new_year_data(df):\n",
    "    df = df[(df.month != 1) | (df.day != 27)]\n",
    "    df = df[(df.month != 1) | (df.day != 28)]\n",
    "    df = df[(df.month != 1) | (df.day != 29)]\n",
    "    df = df[(df.month != 1) | (df.day != 30)]\n",
    "    df = df[(df.month != 1) | (df.day != 31)]\n",
    "    df = df[(df.month != 2) | (df.day != 1)]\n",
    "    df = df[(df.month != 2) | (df.day != 2)]\n",
    "    return df\n",
    "\n",
    "def remove_other_hours_data(df):\n",
    "    df = df[(df.hour != 0)]\n",
    "    df = df[(df.hour != 1)]\n",
    "    df = df[(df.hour != 2)]\n",
    "    df = df[(df.hour != 3)]\n",
    "    df = df[(df.hour != 4)]\n",
    "    df = df[(df.hour != 5)]\n",
    "    df = df[(df.hour != 6)]\n",
    "    df = df[(df.hour != 7)]\n",
    "    df = df[(df.hour != 8)]\n",
    "    df = df[(df.hour != 23)]\n",
    "    return df\n",
    "\n",
    "def handle_na_car_number(df, use_full_data, use_avg_car_number):\n",
    "    if use_full_data:\n",
    "        df.fillna(0, inplace = True)\n",
    "        if use_avg_car_number:\n",
    "            df = update_car_number_to_avg_if_zero(df)\n",
    "    else:\n",
    "        df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# update car number to average if zero (per grid/per weekday/per hour)\n",
    "def update_car_number_to_avg_if_zero(df):\n",
    "    # generate average car number dataframe\n",
    "    avg_car = df.drop(columns=feature_drop_to_calc_avg_car_number)\n",
    "    avg_car = avg_car.groupby(['hour', 'weekday','grid_id'], as_index=False).mean()\n",
    "    avg_car['car_number'] = avg_car.car_number.round()\n",
    "    avg_car = avg_car.rename(columns={'car_number': 'avg_car_number'})\n",
    "    # merge with traing dataframe\n",
    "    df = pd.merge(df, avg_car, on=['grid_id','weekday','hour'], how='left')\n",
    "    # found car_number = 0 row and set to average car number\n",
    "    car_number_index = df.car_number == 0\n",
    "    df.loc[car_number_index,'car_number'] = df.loc[car_number_index, 'avg_car_number']\n",
    "    # drop avg_car_number\n",
    "    df = df.drop(columns=['avg_car_number'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>grid_id</th>\n",
       "      <th>temperture</th>\n",
       "      <th>rainy</th>\n",
       "      <th>holiday</th>\n",
       "      <th>car_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  weekday  grid_id  temperture  rainy  holiday  \\\n",
       "0  2017      1    2     9        0        1          13      0        1   \n",
       "1  2017      1    2     9        0        2          13      0        1   \n",
       "2  2017      1    2     9        0        3          13      0        1   \n",
       "3  2017      1    2     9        0        4          13      0        1   \n",
       "4  2017      1    2     9        0        6          13      0        1   \n",
       "\n",
       "   car_number  \n",
       "0        20.0  \n",
       "1         7.0  \n",
       "2         4.0  \n",
       "3         3.0  \n",
       "4         9.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_phase1_data(use_full_data=False, use_avg_car_number=False)\n",
    "train = pd.read_csv(training_features_filepath)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating test features for submission\n",
    "\n",
    "- from 20170313 to 20170326 2 weeks data\n",
    "- 9<=hour<=22's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_submission_file(start_date, end_date, start_time, end_time, start_gid, end_gid):\n",
    "    # define arrays\n",
    "    grid_id = []\n",
    "    dates = []\n",
    "    hours = []\n",
    "    # generate grid id, date and hour according to criteria\n",
    "    for date in range(start_date, end_date+1):\n",
    "        for time in range(start_time, end_time+1):\n",
    "            for gid in range(start_gid, end_gid+1):\n",
    "                grid_id.append(gid)\n",
    "                dates.append('201703' + str(date))\n",
    "                hours.append(time)\n",
    "    # genreate dataframe            \n",
    "    df = pd.DataFrame(data={'grid_id': grid_id, 'date': dates, 'hour': hours})\n",
    "    df['car_number'] = 0\n",
    "    df=df.reindex(columns=['grid_id','date','hour','car_number'])\n",
    "    # write to csv\n",
    "    df.to_csv(submission_filepath, index=False) \n",
    "\n",
    "\n",
    "def preprocess_test_data():\n",
    "    test = pd.read_csv(submission_filepath)\n",
    "    weather = preprocess_weather_data()\n",
    "    df = pd.merge(test, weather, on=['date', 'hour'], how='left')\n",
    "    df.to_csv(test_features_filepath, columns=feature_columns, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>grid_id</th>\n",
       "      <th>temperture</th>\n",
       "      <th>rainy</th>\n",
       "      <th>holiday</th>\n",
       "      <th>car_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  weekday  grid_id  temperture  rainy  holiday  \\\n",
       "0  2017      3   13     9        0        1           9      1        0   \n",
       "1  2017      3   13     9        0        2           9      1        0   \n",
       "2  2017      3   13     9        0        3           9      1        0   \n",
       "3  2017      3   13     9        0        4           9      1        0   \n",
       "4  2017      3   13     9        0        5           9      1        0   \n",
       "\n",
       "   car_number  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample_submission_file(start_date=13, end_date=26, start_time=9, end_time=22, start_gid=1, end_gid=50)\n",
    "\n",
    "preprocess_test_data()\n",
    "test = pd.read_csv(test_features_filepath)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append average speed to train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>grid_id</th>\n",
       "      <th>temperture</th>\n",
       "      <th>rainy</th>\n",
       "      <th>holiday</th>\n",
       "      <th>speed</th>\n",
       "      <th>car_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  weekday  grid_id  temperture  rainy  holiday  \\\n",
       "0  2017      1    2     9        0        1          13      0        1   \n",
       "1  2017      1    2     9        0        2          13      0        1   \n",
       "2  2017      1    2     9        0        3          13      0        1   \n",
       "3  2017      1    2     9        0        4          13      0        1   \n",
       "4  2017      1    2     9        0        6          13      0        1   \n",
       "\n",
       "   speed  car_number  \n",
       "0     21        20.0  \n",
       "1     16         7.0  \n",
       "2     22         4.0  \n",
       "3     72         3.0  \n",
       "4     41         9.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_avg_speed_to_train_and_test()\n",
    "# show trian data after append with avgerage speed\n",
    "train = pd.read_csv(training_features_filepath)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>grid_id</th>\n",
       "      <th>temperture</th>\n",
       "      <th>rainy</th>\n",
       "      <th>holiday</th>\n",
       "      <th>speed</th>\n",
       "      <th>car_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  weekday  grid_id  temperture  rainy  holiday  \\\n",
       "0  2017      3   13     9        0        1           9      1        0   \n",
       "1  2017      3   13     9        0        2           9      1        0   \n",
       "2  2017      3   13     9        0        3           9      1        0   \n",
       "3  2017      3   13     9        0        4           9      1        0   \n",
       "4  2017      3   13     9        0        5           9      1        0   \n",
       "\n",
       "   speed  car_number  \n",
       "0     21           0  \n",
       "1     16           0  \n",
       "2     22           0  \n",
       "3     72           0  \n",
       "4     72           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show test data after append with avgerage speed\n",
    "test = pd.read_csv(test_features_filepath)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When cluster is 3, score is 69941.19014081002\n",
      "When cluster is 4, score is 60056.08231337371\n",
      "When cluster is 5, score is 52836.312728872304\n",
      "When cluster is 6, score is 46095.53555225386\n",
      "When cluster is 7, score is 42863.13478967278\n",
      "When cluster is 8, score is 40605.82019899379\n",
      "When cluster is 9, score is 38390.79426651683\n",
      "When cluster is 10, score is 36654.21364336126\n",
      "When cluster is 11, score is 34424.49653881763\n",
      "When cluster is 12, score is 33427.47881870069\n",
      "When cluster is 13, score is 32031.98248384285\n",
      "When cluster is 14, score is 32114.303971560035\n",
      "When cluster is 15, score is 30475.719484839923\n",
      "When cluster is 16, score is 29656.18722364567\n",
      "When cluster is 17, score is 29673.0180910773\n",
      "When cluster is 18, score is 27633.084556455735\n",
      "When cluster is 19, score is 27543.59374401571\n",
      "When cluster is 20, score is 26349.71657066581\n",
      "When cluster is 21, score is 26697.789528841637\n",
      "When cluster is 22, score is 25055.10085613132\n",
      "When cluster is 23, score is 25546.237473946545\n",
      "When cluster is 24, score is 24860.057173366764\n",
      "When cluster is 25, score is 24485.93040606983\n",
      "When cluster is 26, score is 23903.071801782367\n",
      "When cluster is 27, score is 23889.848206967432\n",
      "When cluster is 28, score is 22548.679262121746\n",
      "When cluster is 29, score is 22732.428711777684\n",
      "When cluster is 30, score is 22558.199943723597\n",
      "When cluster is 31, score is 21828.19581427121\n",
      "When cluster is 32, score is 21261.74660115316\n",
      "When cluster is 33, score is 21362.815545395762\n",
      "When cluster is 34, score is 20849.560717027205\n",
      "When cluster is 35, score is 20529.53978629471\n",
      "When cluster is 36, score is 20078.469969152582\n",
      "When cluster is 37, score is 19809.249013810702\n",
      "When cluster is 38, score is 19823.656019791095\n",
      "When cluster is 39, score is 19542.101949883476\n",
      "When cluster is 40, score is 19195.036255661216\n",
      "When cluster is 41, score is 18909.607698104566\n",
      "When cluster is 42, score is 18600.916376251338\n",
      "When cluster is 43, score is 18355.91709852436\n",
      "When cluster is 44, score is 17852.11572965642\n",
      "When cluster is 45, score is 17913.980032833362\n",
      "When cluster is 46, score is 17874.23444298508\n",
      "When cluster is 47, score is 17809.85495719705\n",
      "When cluster is 48, score is 17551.028726618122\n",
      "When cluster is 49, score is 17184.385495653838\n",
      "When cluster is 50, score is 17335.109720198187\n",
      "When cluster is 51, score is 16816.527077494135\n",
      "When cluster is 52, score is 16790.403326644286\n",
      "When cluster is 53, score is 16540.702323192876\n",
      "When cluster is 54, score is 16589.321460667124\n",
      "When cluster is 55, score is 16016.975780666924\n",
      "When cluster is 56, score is 16171.626481336074\n",
      "When cluster is 57, score is 15969.31426210714\n",
      "When cluster is 58, score is 16005.535948497065\n",
      "When cluster is 59, score is 15359.295530537445\n",
      "When cluster is 60, score is 15646.37954070781\n",
      "When cluster is 61, score is 15520.648234543807\n",
      "When cluster is 62, score is 14930.835269003093\n",
      "When cluster is 63, score is 15061.155319080846\n",
      "When cluster is 64, score is 14427.849066545527\n",
      "When cluster is 65, score is 15004.824634053173\n",
      "When cluster is 66, score is 14673.036893289176\n",
      "When cluster is 67, score is 14634.16880020607\n",
      "When cluster is 68, score is 14590.545750917487\n",
      "When cluster is 69, score is 14486.082551232543\n",
      "When cluster is 70, score is 14448.89192507672\n",
      "When cluster is 71, score is 14198.099939728905\n",
      "When cluster is 72, score is 14302.926673404409\n",
      "When cluster is 73, score is 14040.791917967077\n",
      "When cluster is 74, score is 13499.441369314774\n",
      "When cluster is 75, score is 13991.29831123008\n",
      "When cluster is 76, score is 13902.737780176065\n",
      "When cluster is 77, score is 13806.277160449765\n",
      "When cluster is 78, score is 13835.557959221513\n",
      "When cluster is 79, score is 13576.797926046942\n",
      "When cluster is 80, score is 13429.912663793668\n",
      "When cluster is 81, score is 12795.850006157647\n",
      "When cluster is 82, score is 13297.606915011422\n",
      "When cluster is 83, score is 13257.913635677047\n",
      "When cluster is 84, score is 12842.961803713932\n",
      "When cluster is 85, score is 13189.725643996258\n",
      "When cluster is 86, score is 13077.175026325407\n",
      "When cluster is 87, score is 12944.576746006906\n",
      "When cluster is 88, score is 12365.036230250827\n",
      "When cluster is 89, score is 12841.080623166425\n",
      "When cluster is 90, score is 12871.125176176816\n",
      "When cluster is 91, score is 12641.514646793668\n",
      "When cluster is 92, score is 12763.865578166444\n",
      "When cluster is 93, score is 12675.90608285249\n",
      "When cluster is 94, score is 12341.621840972624\n",
      "When cluster is 95, score is 12591.62774859018\n",
      "When cluster is 96, score is 12389.345900605924\n",
      "When cluster is 97, score is 12400.402101810037\n",
      "When cluster is 98, score is 12280.220975759732\n",
      "When cluster is 99, score is 12252.636394668918\n",
      "When cluster is 100, score is 12109.555073653511\n",
      "When cluster is 101, score is 11994.57999918114\n",
      "When cluster is 102, score is 12215.455883461247\n",
      "When cluster is 103, score is 12099.704970761424\n",
      "When cluster is 104, score is 11896.844149661985\n",
      "When cluster is 105, score is 11889.494948725101\n",
      "When cluster is 106, score is 11894.43725989486\n",
      "When cluster is 107, score is 11801.465292872002\n",
      "When cluster is 108, score is 11666.399880370183\n",
      "When cluster is 109, score is 11594.48614313151\n",
      "When cluster is 110, score is 11709.537677993212\n",
      "When cluster is 111, score is 11696.9955141191\n",
      "When cluster is 112, score is 11697.40860967943\n",
      "When cluster is 113, score is 11539.577637934197\n",
      "When cluster is 114, score is 11408.370829540674\n",
      "When cluster is 115, score is 11353.627984987279\n",
      "When cluster is 116, score is 11361.213264120583\n",
      "When cluster is 117, score is 11364.719300908026\n",
      "When cluster is 118, score is 11301.81616065831\n",
      "When cluster is 119, score is 11214.136634535205\n",
      "When cluster is 120, score is 11301.762905650367\n",
      "When cluster is 121, score is 11148.979376010875\n",
      "When cluster is 122, score is 10627.864266254395\n",
      "When cluster is 123, score is 10493.61013495747\n",
      "When cluster is 124, score is 11137.889806040559\n",
      "When cluster is 125, score is 11014.056663517335\n",
      "When cluster is 126, score is 11081.458628463592\n",
      "When cluster is 127, score is 11002.314295384962\n",
      "When cluster is 128, score is 10867.64463710412\n",
      "When cluster is 129, score is 10909.119920248544\n",
      "When cluster is 130, score is 10740.391038422256\n",
      "When cluster is 131, score is 10860.904129548311\n",
      "When cluster is 132, score is 10835.953724555668\n",
      "When cluster is 133, score is 10055.490930571768\n",
      "When cluster is 134, score is 10601.20697206389\n",
      "When cluster is 135, score is 10709.001331838217\n",
      "When cluster is 136, score is 10440.827944242143\n",
      "When cluster is 137, score is 10590.128577951931\n",
      "When cluster is 138, score is 10668.892282916057\n",
      "When cluster is 139, score is 10617.211886335259\n",
      "When cluster is 140, score is 10446.46693613468\n",
      "When cluster is 141, score is 10396.806529246893\n",
      "When cluster is 142, score is 10376.46657185338\n",
      "When cluster is 143, score is 10403.437285108013\n",
      "When cluster is 144, score is 10369.37714106796\n",
      "When cluster is 145, score is 10314.097859930967\n",
      "When cluster is 146, score is 10241.022898829244\n",
      "When cluster is 147, score is 10311.846219586858\n",
      "When cluster is 148, score is 10272.31152114124\n",
      "When cluster is 149, score is 10206.997803647168\n",
      "When cluster is 150, score is 9433.236034552021\n",
      "When cluster is 151, score is 10164.241884458574\n",
      "When cluster is 152, score is 10062.258548027963\n",
      "When cluster is 153, score is 10144.630281576934\n",
      "When cluster is 154, score is 10146.302694822281\n",
      "When cluster is 155, score is 10122.064748724137\n",
      "When cluster is 156, score is 10003.14172490251\n",
      "When cluster is 157, score is 9990.955159377352\n",
      "When cluster is 158, score is 9999.707426650199\n",
      "When cluster is 159, score is 10007.243170653384\n",
      "When cluster is 160, score is 9932.348996448969\n",
      "When cluster is 161, score is 9849.354096653014\n",
      "When cluster is 162, score is 9843.155392136576\n",
      "When cluster is 163, score is 9833.773246385841\n",
      "When cluster is 164, score is 9906.60440060135\n",
      "When cluster is 165, score is 9079.339521084414\n",
      "When cluster is 166, score is 9784.22627189764\n",
      "When cluster is 167, score is 9682.307715409612\n",
      "When cluster is 168, score is 9666.504907689385\n",
      "When cluster is 169, score is 9723.256335597378\n",
      "When cluster is 170, score is 9642.370060293562\n",
      "When cluster is 171, score is 9608.089428893349\n",
      "When cluster is 172, score is 8944.83195138197\n",
      "When cluster is 173, score is 9493.28550648626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When cluster is 174, score is 9517.017899948867\n",
      "When cluster is 175, score is 9563.098994727326\n",
      "When cluster is 176, score is 9384.198037921822\n",
      "When cluster is 177, score is 9489.3769225814\n",
      "When cluster is 178, score is 9349.678618051505\n",
      "When cluster is 179, score is 9394.252542887756\n",
      "When cluster is 180, score is 9503.063861693532\n",
      "When cluster is 181, score is 9306.922407675866\n",
      "When cluster is 182, score is 9408.895809519716\n",
      "When cluster is 183, score is 9272.745124308936\n",
      "When cluster is 184, score is 9295.196195107159\n",
      "When cluster is 185, score is 9324.559670386781\n",
      "When cluster is 186, score is 9326.742448471014\n",
      "When cluster is 187, score is 8545.602688116405\n",
      "When cluster is 188, score is 9263.431689536043\n",
      "When cluster is 189, score is 9224.44362082947\n",
      "When cluster is 190, score is 9284.115731778535\n",
      "When cluster is 191, score is 9142.300435974843\n",
      "When cluster is 192, score is 9153.427261047122\n",
      "When cluster is 193, score is 9080.547343243301\n",
      "When cluster is 194, score is 9096.884443923562\n",
      "When cluster is 195, score is 9092.734856232564\n",
      "When cluster is 196, score is 9085.7746920888\n",
      "When cluster is 197, score is 9061.503924415236\n",
      "When cluster is 198, score is 9005.869995317304\n",
      "When cluster is 199, score is 9045.873282467273\n",
      "When cluster is 200, score is 8916.057511947878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans,KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "import time\n",
    "\n",
    "train_for_clustering = train.drop(columns=['year','month','day','grid_id','car_number'])\n",
    "\n",
    "for n_clusters in range(3, 201):\n",
    "    mbk = MiniBatchKMeans(init='k-means++', n_clusters=n_clusters, batch_size=128 ,n_init=10, max_no_improvement=10, verbose=0)\n",
    "    mbk.fit(train_for_clustering)\n",
    "    pred = mbk.predict(train_for_clustering)\n",
    "    score = calinski_harabaz_score(train_for_clustering, pred)\n",
    "    print(\"When cluster is {}, score is {}\".format(n_clusters, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
