{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eddef5f-7622-41be-a1d7-3fe8b20326dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c590e4-e552-4ab8-8403-5c07528c74df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMWithLMHeadModel were not initialized from the model checkpoint at xlm-clm-enfr-1024 and are newly initialized: ['transformer.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# download tokenizer and model\n",
    "tokenizer = XLMTokenizer.from_pretrained(\"xlm-clm-enfr-1024\")\n",
    "model = XLMWithLMHeadModel.from_pretrained(\"xlm-clm-enfr-1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9a942d-9e7c-493c-aa7e-4930abf3c3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 0, 'fr': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display supported language and id\n",
    "tokenizer.lang2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d9845f7-c846-4d08-bef5-1ad901b03f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  4018,  5545, 51104,    32,   308,    18,     1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an example input\n",
    "input_ids = torch.tensor([tokenizer.encode(\"Wikipedia was used to\")])  # batch size of 1\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be267b6-f127-4c3f-a7b1-f5cd99aebc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), torch.Size([1, 8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve language id -> 0\n",
    "language_id = tokenizer.lang2id[\"en\"] \n",
    "\n",
    "# torch.tensor([0, 0, 0, ..., 0])\n",
    "langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])\n",
    "\n",
    "# We reshape it to be of size (batch_size, sequence_length)\n",
    "langs = langs.view(1, -1)  # is now of shape [1, sequence_length] (we have a batch size of 1)\\\n",
    "\n",
    "langs, langs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e46528-8537-470b-a569-e02888c58f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -6.3665,  10.7176,  -6.3754,  ...,  -6.1219,  -6.3775,  -6.0470],\n",
       "         [-13.8973,  -3.1509, -13.8749,  ..., -14.6975, -12.9415, -13.8252],\n",
       "         [ -9.2461,   4.8444,  -9.6047,  ..., -10.5616,  -8.2646,  -9.9838],\n",
       "         ...,\n",
       "         [-12.1487,   9.7573, -12.0884,  ..., -13.0167, -11.7700, -10.6408],\n",
       "         [-11.5067,   4.1504, -11.6619,  ..., -12.0130, -11.2718, -10.8311],\n",
       "         [ -8.4061,   6.6820,  -8.5521,  ...,  -8.2401,  -8.5305,  -8.3125]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass the input ids and language embedding to the model\n",
    "outputs = model(input_ids, langs=langs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013c4fe-e046-4506-bb00-5ac71900d9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('logits', tensor([[[ -6.3665,  10.7176,  -6.3754,  ...,  -6.1219,  -6.3775,  -6.0470],\n",
      "         [-13.8973,  -3.1509, -13.8749,  ..., -14.6975, -12.9415, -13.8252],\n",
      "         [ -9.2461,   4.8444,  -9.6047,  ..., -10.5616,  -8.2646,  -9.9838],\n",
      "         ...,\n",
      "         [-12.1487,   9.7573, -12.0884,  ..., -13.0167, -11.7700, -10.6408],\n",
      "         [-11.5067,   4.1504, -11.6619,  ..., -12.0130, -11.2718, -10.8311],\n",
      "         [ -8.4061,   6.6820,  -8.5521,  ...,  -8.2401,  -8.5305,  -8.3125]]],\n",
      "       grad_fn=<ViewBackward0>))\n"
     ]
    }
   ],
   "source": [
    "hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85492dbc-c649-41b0-8093-a0fccc39022c",
   "metadata": {},
   "source": [
    "### Try sentence transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af353d01-cb2d-47aa-bd6b-b2036f1986b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef63bae-1b40-4ca6-9370-7e73e6076ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.58 s, sys: 460 ms, total: 5.04 s\n",
      "Wall time: 7.93 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sumar números de varios dígitos: 48,029+233,930 ',\n",
       " 'Trovare i fattori di un numero',\n",
       " 'Sumar curvas de demanda',\n",
       " 'Nado de aproximação',\n",
       " 'geometry-m3-topic-a-overview.pdf',\n",
       " '5.12E: Regulation of the Calvin Cycle',\n",
       " 'Reflexionemos sobre lo que vemos y escuchamos',\n",
       " 'अंग्रेजी ओके प्लीज 1.2',\n",
       " '4.E: Genomes and Chromosomes (Exercises)',\n",
       " 'La banca 12: los bonos del tesoro (deuda pública)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "contents = pd.read_csv('./data/content.csv')\n",
    "contents['title'] = contents['title'].fillna('No title exist')\n",
    "title_sentences = list(contents.title.values)\n",
    "title_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dcb4e70-4787-4beb-83fe-42c4cc9eff22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[-0.0394,  0.0246, -0.0035,  ...,  0.0677,  0.0117, -0.0330],\n",
      "        [-0.0439, -0.0270, -0.0044,  ...,  0.0714,  0.0114, -0.0300],\n",
      "        [-0.0217,  0.0136, -0.0046,  ...,  0.0016, -0.0647, -0.0364],\n",
      "        ...,\n",
      "        [-0.0347,  0.0291, -0.0065,  ...,  0.0083, -0.0276, -0.0389],\n",
      "        [-0.0064,  0.0167, -0.0035,  ...,  0.0052, -0.0050, -0.0418],\n",
      "        [-0.0396,  0.0388, -0.0047,  ...,  0.0280, -0.0131,  0.0163]])\n",
      "CPU times: user 1.06 s, sys: 0 ns, total: 1.06 s\n",
      "Wall time: 47.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(title_sentences[:10], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ac957dc-b7dd-46d3-b0ac-cd34e06bfd03",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2809074728.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    **encoded_input\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "**encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e4ba18-c39a-437a-98da-39e952c8e7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
